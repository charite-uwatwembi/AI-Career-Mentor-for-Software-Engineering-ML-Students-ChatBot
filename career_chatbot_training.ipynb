{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Career Q&A Chatbot - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.30.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.39.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (75.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sacrebleu) (5.3.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: aiohttp~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.11.11)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (5.4.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.103.2)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client>=0.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.7.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.17)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.22.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (11.0.3)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp~=3.0->gradio) (1.18.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.5.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (1.13.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (3.7.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->gradio) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->gradio) (0.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from portalocker->sacrebleu) (308)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx->gradio) (1.3.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.20.1)\n",
      "Requirement already satisfied: uc-micro-py in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Using cached torch-2.6.0-cp311-cp311-win_amd64.whl (204.2 MB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/6.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.2 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 1.8/6.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.1/6.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 3.7/6.2 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.9/6.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 2.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 1.6 MB/s eta 0:00:00\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 762.0 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.5/1.7 MB 762.0 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.8/1.7 MB 713.3 kB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.0/1.7 MB 739.8 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 739.8 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.7 MB 739.8 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 657.8 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 657.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 625.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 615.2 kB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 262.1/536.2 kB ? eta -:--:--\n",
      "   -------------------------------------- 536.2/536.2 kB 566.2 kB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers tensorflow pandas scikit-learn sacrebleu gradio torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: Index(['role', 'question', 'answer'], dtype='object')\n",
      "\n",
      "Sample data:\n",
      "              role                                           question  \\\n",
      "0  Data Scientist                     What does a Data Scientist do?   \n",
      "1  Data Scientist  What are the main responsibilities of a Data S...   \n",
      "2  Data Scientist  What is the job description for a Data Scientist?   \n",
      "3  Data Scientist  What skills are required to become a Data Scie...   \n",
      "4  Data Scientist  What are the essential skills for a successful...   \n",
      "\n",
      "                                              answer  \n",
      "0  A Data Scientist extracts meaningful insights ...  \n",
      "1  Responsibilities include data cleaning, analyz...  \n",
      "2  A Data Scientist is responsible for collecting...  \n",
      "3  Skills required include expertise in Python or...  \n",
      "4  A successful Data Scientist needs strong analy...  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"Data/CareerDataset.csv\")\n",
    "print(\"Dataset columns:\", df.columns)\n",
    "print(\"\\nSample data:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"question\", \"answer\"]]\n",
    "\n",
    "# Add prefix for T5 task conditioning\n",
    "df[\"input_text\"] = \"answer career question: \" + df[\"question\"]\n",
    "df[\"target_text\"] = df[\"answer\"]\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function (fixed for tuples)\n",
    "def tokenize_data(input_text_tensor, target_text_tensor):\n",
    "    input_text = input_text_tensor.numpy().decode(\"utf-8\")\n",
    "    target_text = target_text_tensor.numpy().decode(\"utf-8\")\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    targets = tokenizer(\n",
    "        target_text,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return (\n",
    "        inputs[\"input_ids\"].squeeze(), \n",
    "        inputs[\"attention_mask\"].squeeze(), \n",
    "        targets[\"input_ids\"].squeeze()\n",
    "    )\n",
    "\n",
    "# Map wrapper for tuples\n",
    "def map_wrapper(input_text, target_text):\n",
    "    return tf.py_function(\n",
    "        tokenize_data,\n",
    "        [input_text, target_text],\n",
    "        (tf.int32, tf.int32, tf.int32)\n",
    "    )\n",
    "\n",
    "# Convert tuples to dict\n",
    "def to_dict(input_ids, attention_mask, labels):\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Dataset pipelines\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (train_df[\"input_text\"], train_df[\"target_text\"])\n",
    "    )\n",
    "    .map(map_wrapper)\n",
    "    .map(to_dict)\n",
    "    .shuffle(1000)\n",
    "    .batch(8)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (val_df[\"input_text\"], val_df[\"target_text\"])\n",
    "    )\n",
    "    .map(map_wrapper)\n",
    "    .map(to_dict)\n",
    "    .batch(8)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_wrapper(input_text, target_text):\n",
    "    # Use tf.py_function with output signature as a TUPLE of types\n",
    "    return tf.py_function(\n",
    "        tokenize_data,\n",
    "        [input_text, target_text],\n",
    "        (tf.int32, tf.int32, tf.int32)  # Output types for input_ids, attention_mask, labels\n",
    "    )\n",
    "\n",
    "# Convert tuples to dictionaries in the dataset pipeline\n",
    "def to_dict(input_ids, attention_mask, labels):\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Create datasets\n",
    "# Create datasets with TUPLE structure (input_text, target_text)\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (train_df[\"input_text\"], train_df[\"target_text\"])\n",
    "    )\n",
    "    .map(map_wrapper)\n",
    "    .batch(8)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (val_df[\"input_text\"], val_df[\"target_text\"])\n",
    "    )\n",
    "    .map(map_wrapper)\n",
    "    .batch(8)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1658, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer 'tft5_for_conditional_generation' (type TFT5ForConditionalGeneration).\n    \n    in user code:\n    \n        File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1298, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 1340, in call  *\n            encoder_outputs = self.encoder(\n        File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        OperatorNotAllowedInGraphError: Exception encountered when calling layer 'encoder' (type TFT5MainLayer).\n        \n        in user code:\n        \n            File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1298, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 693, in call  *\n                batch_size, seq_length = input_shape\n        \n            OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n        \n        \n        Call arguments received by layer 'encoder' (type TFT5MainLayer):\n          • input_ids=tf.Tensor(shape=<unknown>, dtype=int32)\n          • attention_mask=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • inputs_embeds=None\n          • head_mask=None\n          • encoder_head_mask=None\n          • past_key_values=None\n          • use_cache=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer 'tft5_for_conditional_generation' (type TFT5ForConditionalGeneration):\n      • input_ids={'input_ids': 'tf.Tensor(shape=<unknown>, dtype=int32)', 'labels': 'tf.Tensor(shape=<unknown>, dtype=int32)'}\n      • attention_mask=None\n      • decoder_input_ids=None\n      • decoder_attention_mask=None\n      • head_mask=None\n      • decoder_head_mask=None\n      • encoder_outputs=None\n      • past_key_values=None\n      • inputs_embeds=None\n      • decoder_inputs_embeds=None\n      • labels=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[0;32m     16\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1200\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1658, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    OperatorNotAllowedInGraphError: Exception encountered when calling layer 'tft5_for_conditional_generation' (type TFT5ForConditionalGeneration).\n    \n    in user code:\n    \n        File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1298, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 1340, in call  *\n            encoder_outputs = self.encoder(\n        File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        OperatorNotAllowedInGraphError: Exception encountered when calling layer 'encoder' (type TFT5MainLayer).\n        \n        in user code:\n        \n            File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1298, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"c:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\t5\\modeling_tf_t5.py\", line 693, in call  *\n                batch_size, seq_length = input_shape\n        \n            OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n        \n        \n        Call arguments received by layer 'encoder' (type TFT5MainLayer):\n          • input_ids=tf.Tensor(shape=<unknown>, dtype=int32)\n          • attention_mask=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • inputs_embeds=None\n          • head_mask=None\n          • encoder_head_mask=None\n          • past_key_values=None\n          • use_cache=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer 'tft5_for_conditional_generation' (type TFT5ForConditionalGeneration):\n      • input_ids={'input_ids': 'tf.Tensor(shape=<unknown>, dtype=int32)', 'labels': 'tf.Tensor(shape=<unknown>, dtype=int32)'}\n      • attention_mask=None\n      • decoder_input_ids=None\n      • decoder_attention_mask=None\n      • head_mask=None\n      • decoder_head_mask=None\n      • encoder_outputs=None\n      • past_key_values=None\n      • inputs_embeds=None\n      • decoder_inputs_embeds=None\n      • labels=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "\n",
    "# Load model and tokenizer (fixed)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-small\", from_pt=True)\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
